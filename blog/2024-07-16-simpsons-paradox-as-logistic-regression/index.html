<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>Simpson’s Paradox as a Logistic Regression</title>
		<meta name="description" content="Data Scientist, San Francisco">
		<link rel="alternate" href="/feed/feed.xml" type="application/atom+xml" title="Nina B. Zumel">
		<link rel="alternate" href="/feed/feed.json" type="application/json" title="Nina B. Zumel">
		<script src="https://kit.fontawesome.com/9bbe6f85f9.js" crossorigin="anonymous"></script>
		
		<style>/**
 * okaidia theme for JavaScript, CSS and HTML
 * Loosely based on Monokai textmate theme by http://www.monokai.nl/
 * @author ocodia
 */

code[class*="language-"],
pre[class*="language-"] {
	color: #f8f8f2;
	background: none;
	text-shadow: 0 1px rgba(0, 0, 0, 0.3);
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	font-size: 1em;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
	border-radius: 0.3em;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #272822;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: #8292a2;
}

.token.punctuation {
	color: #f8f8f2;
}

.token.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.constant,
.token.symbol,
.token.deleted {
	color: #f92672;
}

.token.boolean,
.token.number {
	color: #ae81ff;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #a6e22e;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string,
.token.variable {
	color: #f8f8f2;
}

.token.atrule,
.token.attr-value,
.token.function,
.token.class-name {
	color: #e6db74;
}

.token.keyword {
	color: #66d9ef;
}

.token.regex,
.token.important {
	color: #fd971f;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}
/*
 * New diff- syntax
 */

pre[class*="language-diff-"] {
	--eleventy-code-padding: 1.25em;
	padding-left: var(--eleventy-code-padding);
	padding-right: var(--eleventy-code-padding);
}
.token.deleted {
	background-color: hsl(0, 51%, 37%);
	color: inherit;
}
.token.inserted {
	background-color: hsl(126, 31%, 39%);
	color: inherit;
}

/* Make the + and - characters unselectable for copy/paste */
.token.prefix.unchanged,
.token.prefix.inserted,
.token.prefix.deleted {
	-webkit-user-select: none;
	user-select: none;
	display: inline-flex;
	align-items: center;
	justify-content: center;
	padding-top: 2px;
	padding-bottom: 2px;
}
.token.prefix.inserted,
.token.prefix.deleted {
	width: var(--eleventy-code-padding);
	background-color: rgba(0,0,0,.2);
}

/* Optional: full-width background color */
.token.inserted:not(.prefix),
.token.deleted:not(.prefix) {
	display: block;
	margin-left: calc(-1 * var(--eleventy-code-padding));
	margin-right: calc(-1 * var(--eleventy-code-padding));
	text-decoration: none; /* override del, ins, mark defaults */
	color: inherit; /* override del, ins, mark defaults */
}
/* minimal implementation; just plain text in the margin, no blockquotes, code, etc */
/* only (unnumbered) margin notes, no sidenotes */
/* stripped down from https://github.com/edwardtufte/tufte-css */

/* need this for correct sidenote numbering; but I'm not using sidenotes */
/*
body {
    counter-reset: sidenote-counter; 
} 
*/

/* since I imagine these will change with different templates */
:root {
    --content-width: 65%;
    --image-padding: 5%;
    --image-max: 60%;  /* total image+padding <= content-width */
    --notewidth: 30%; 
    /* content-width + notewidth <  100%. I think you should leave some wiggle room. */
    --note-right-margin: -45%; 
    /* if this margin is -(notewidth), the note will start just on the right border of the text */
    /* so push it a little to the right (more negative) */
}

article {
	padding-top: 1rem; 
}

/* make room for the notes in the article container */
article > p,
article > pre,
article > ul {
    width: var(--content-width);
}

/* blockquotes should be a little shorter */
article > blockquote {
    width: calc(var(--content-width) * 0.8);
}

/* keep images/captions in the text column, rather than centered in the article container */
article > img {
    margin-left: 0;
    padding-left: var(--image-padding);
    max-width: var(--image-max); 
}

article > p.caption {
	text-align: left;
    padding-left: var(--image-padding);
	font-style: italic;
	font-size: 0.9em;
	color: #9B9C9D;
 }

 /* finally, the margin note */
.marginnote {    
    float: right;
    clear: right;
    width: var(--notewidth);         
    margin-right: var(--note-right-margin);
    margin-top: 0.3rem;
    margin-bottom: 0;
    font-size: 0.8rem;
    line-height: 1.3;
    vertical-align: baseline;
    position: relative;
}


input.margin-toggle {
    display: none;
}


label.margin-toggle {    
    display: none;

}

/* The mobile fallback: */
/* making max-width bigger makes the note fall inline sooner */
@media (max-width: 768px) {  
    body {
        width: 84%;
        padding-left: 8%;
        padding-right: 8%;
    }

    hr,
    article > p,
    article > blockquote,
    article > pre {
        width: 100%;
    }

    label.margin-toggle {
        display: inline;
    }
       
    .marginnote {           
         display: none;        
        }    

      
    .margin-toggle:checked + .marginnote {            
        display: block;            
        float: left;            
        left: 1rem;            
        clear: both;            
        width: 95%;            
        margin: 1rem 2.5%;            
        vertical-align: baseline;            
        position: relative;        
    }
    label {
        cursor: pointer;
    }
}
* { box-sizing: border-box; }
/* Defaults */
:root {
	--font-family: -apple-system, system-ui, sans-serif;
	--font-family-monospace: Consolas, Menlo, Monaco, Andale Mono WT, Andale Mono, Lucida Console, Lucida Sans Typewriter, DejaVu Sans Mono, Bitstream Vera Sans Mono, Liberation Mono, Nimbus Mono L, Courier New, Courier, monospace;
}

/* Theme colors */
:root {
	--color-gray-20: #e0e0e0;
	--color-gray-50: #C0C0C0;
	--color-gray-70: #4D4D4D;
	--color-gray-90: #333;

	--description-color: #9B9C9D;
	--background-color: #fff;

	--text-color: var(--color-gray-70);
	--text-color-link: #32506d;
	--text-color-link-active: #5f2b48;
	--text-color-link-visited: #17050F;

	--syntax-tab-size: 2;
}

@media (prefers-color-scheme: dark) {
	:root {
		--color-gray-20: #e0e0e0;
		--color-gray-50: #C0C0C0;
		--color-gray-70: #dad8d8;
		--color-gray-90: #dad8d8;

		/* --text-color is assigned to --color-gray-_ above.*/
		--test-color: var(--color-gray-20);
		--text-color-link: #1493fb;
		--text-color-link-active: #6969f7;
		--text-color-link-visited: #a6a6f8;

		--background-color: #15202b;
	}
}


/* Global stylesheet */
* {
	box-sizing: border-box;
}

html,
body {
	padding: 0;
	margin: 0 auto;
	font-family: var(--font-family);
	color: var(--text-color);
	background-color: var(--background-color);
}
html {
	overflow-y: scroll;
}
body {
	max-width: 70em; /* a little wider to accomodate margin notes */
}

/* 
https://css-tricks.com/barebones-css-for-fluid-images/ 
Without this, images generated by eleventy-img will always use the largest available size
-- ie, not be responsive.
*/
img {
	max-width: 100%;
	display: block;
	margin-left: auto;
	margin-right: auto;
  }
  img[width] {
	width: auto; /* Defer to max-width */
  }
  img[width][height] {
	height: auto; /* Preserve aspect ratio */
  }
  
  /* Let SVG scale without boundaries */
  img[src$=".svg"] {
	width: 100%;
	height: auto;
	max-width: none;
  }
  

/* https://www.a11yproject.com/posts/how-to-hide-content/ */
.visually-hidden {
	clip: rect(0 0 0 0);
	clip-path: inset(50%);
	height: 1px;
	overflow: hidden;
	position: absolute;
	white-space: nowrap;
	width: 1px;
}

p:last-child {
	margin-bottom: 0;
}
p {
	line-height: 1.5;
	/* font-size: 1.2em; */
}

p.caption {
	text-align: center;
	font-style: italic;
	font-size: 0.9em;
	color: #9B9C9D;
 }

li {
	line-height: 1.5;
	/* font-size: 1.2em; */
}

a[href] {
	color: var(--text-color-link);
}
a[href]:visited {
	color: var(--text-color-link-visited);
}
a[href]:hover,
a[href]:active {
	color: var(--text-color-link-active);
}

main {
	padding: 1rem;
}
main :first-child {
	margin-top: 0;
}

header {
	border-bottom: 1px dashed var(--color-gray-20);
}
header:after {
	content: "";
	display: table;
	clear: both;
}

.links-nextprev {
	list-style: none;
	border-top: 1px dashed var(--color-gray-20);
	padding: 1em 0;
}

table {
	margin: 1em 0;
}
table td,
table th {
	padding-right: 1em;
}

pre,
code {
	font-family: var(--font-family-monospace);
}
pre:not([class*="language-"]) {
	margin: .5em 0;
	line-height: 1.375; /* 22px /16 */
	-moz-tab-size: var(--syntax-tab-size);
	-o-tab-size: var(--syntax-tab-size);
	tab-size: var(--syntax-tab-size);
	-webkit-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
	direction: ltr;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
}
code {
	word-break: break-all;
}

/*
  Custom containters
*/
div.message-box {
	max-width: 50em; 
	margin-left: auto;
	margin-right: auto;
}



/* Header */
header {
	display: flex;
	gap: 1em .5em;
	flex-wrap: wrap;
	align-items: center;
	padding: 1em;
}
.home-link {
	font-size: 1.5em; /* 24px /16 (I think)*/
	font-weight: 700;
	margin-right: 2em;
}
.home-link:link:not(:hover) {
	text-decoration: none;
}

/* Nav */
.nav {
	display: flex;
	padding: 0;
	margin: 0;
	list-style: none;
}
.nav-item {
	display: inline-block;
	margin-right: 1em;
}
.nav-item a[href]:not(:hover) {
	text-decoration: none;
}
.nav a[href][aria-current="page"] {
	text-decoration: underline;
}

/* Posts list */
.postlist {
	list-style: none;
	padding: 0;
	padding-left: 1.5rem;
	max-width: 50em; /* keep it narrower than the new wider body width */
}
.postlist-item {
	display: flex;
	flex-wrap: wrap;
	align-items: baseline;
	counter-increment: start-from -1;
	margin-bottom: 1em;
}
.postlist-item:before {
	display: inline-block;
	pointer-events: none;
	content: "" counter(start-from, decimal-leading-zero) ". ";
	line-height: 100%;
	text-align: right;
	margin-left: -1.5rem;
}
.postlist-date,
.postlist-item:before {
	font-size: 0.8125em; /* 13px /16 */
	color: var(--color-gray-90);
}
.postlist-date {
	word-spacing: -0.5px;
}
.postlist-link {
	font-size: 1.1875em; /* 19px /16 */
	font-weight: 700;
	flex-basis: calc(100% - 1.5rem);
	padding-left: .25em;
	padding-right: .5em;
	text-underline-position: from-font;
	text-underline-offset: 0;
	text-decoration-thickness: 1px;
}
.postlist-item-active .postlist-link {
	font-weight: bold;
}

/* Tags */
.post-tag {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	text-transform: capitalize;
	font-style: italic;
}
.postlist-item > .post-tag {
	align-self: center;
}

/* Tags list */
.post-metadata {
	display: inline-flex;
	flex-wrap: wrap;
	gap: .5em;
	list-style: none;
	padding: 0;
	margin: 0;
}
.post-metadata time {
	margin-right: 1em;
}

.post-metadata li {
	font-size: 0.875em;
}

/* metadata for posts and talks */

.posttalk-metadata {
	list-style: none;
	padding-left: 0;
	color: var(--description-color);
}

.posttalk-metadata li {
	font-size: 1.1em;
}

/* Direct Links / Markdown Headers */
.header-anchor {
	text-decoration: none;
	font-style: normal;
	font-size: 1em;
	margin-left: .1em;
}
a[href].header-anchor,
a[href].header-anchor:visited {
	color: transparent;
}
a[href].header-anchor:focus,
a[href].header-anchor:hover {
	text-decoration: underline;
}
a[href].header-anchor:focus,
:hover > a[href].header-anchor {
	color: #aaa;
}

h2 + .header-anchor {
	font-size: 1.5em;
}

/* Footer */
hr {
    border: none;
    background-color: #DADADB;
    height: 1px;
    width: 100%;
    margin: 0 auto;
}

@media screen and (max-width: 768px) {
    hr {
        width: 100%;
    }
}

.footer-container {
    display: flex;
    justify-content: space-around;
    align-items: center;
    padding: 2rem 0;
    background-color: var(--background-color0);
	;
}

.footer-container p {
    font-size: 1rem;
    color: #9B9C9D;
}

.footer-container .social_icons {
    display: flex;
    justify-content: space-between;
    align-items: center;
    gap: 0 1rem;
}

.footer-container .social_icons a {
    color: #9B9C9D;
    font-size: 1.5rem;
    transition: all 0.5s ease-in-out;
}

.footer-container .social_icons a:hover {
    color: #DADADB;
}</style>
	</head>
	<body>
		<a href="#skip" class="visually-hidden">Skip to main content</a>

		<header>
			<a href="/" class="home-link">Nina B. Zumel</a>
			<nav>
				<h2 class="visually-hidden">Top level navigation menu</h2>
				<ul class="nav">
					<li class="nav-item"><a href="/pages/professional/">Professional</a></li>
					<li class="nav-item"><a href="/pages/personal/">Personal</a></li>
					<li class="nav-item"><a href="/pages/technical-blogging/">Technical Blogging</a></li>
				</ul>
			</nav>
		</header>

		<main id="skip">
			

<h1>Simpson’s Paradox as a Logistic Regression</h1>

<div class="posttalk-metadata">
  <time datetime="2024-07-16">16 July 2024</time>
</div>
<ul class="post-metadata">
	<li><a href="/tags/data-science/" class="post-tag">data science</a>, </li>
	<li><a href="/tags/statistics/" class="post-tag">statistics</a>, </li>
	<li><a href="/tags/logistic-regression/" class="post-tag">logistic regression</a></li>
</ul>


<article>
<p><a href="https://en.wikipedia.org/wiki/Simpson's_paradox">Simpson’s paradox</a> is
when a trend that is present in various groups of data seems to
disappear or even reverse when those groups are combined. One sees
examples of this often in things like medical trials, and the phenomenon
is generally due to one or more unmodelled confounding variables.</p>
<p>In the course of something else that I was working on, I was trying to
come with an example of a logistic regression analysis, where one of the
coefficients had a clearly incorrect sign. There are several reasons why
this might happen: separation or quasiseparation of the data being the
obvious ones. But Simpson’s paradox is another cause.</p>
<p>I ended up not needing the example, but since I had it, I thought I’d
write it up, since I’ve never seen Simpson’s paradox presented in quite
this way before.</p>
<h2 id="synthetic-example-weight-loss-trial" tabindex="-1">Synthetic Example: Weight Loss Trial <a class="header-anchor" href="#synthetic-example-weight-loss-trial">#</a></h2>
<p>This is a problem statement where we would expect the coefficients of a
logistic regression to be non-negative (except the intercept).</p>
<p>Consider a trial that tests the efficacy of a specific eating regimen
(let’s say 16/8 intermittent fasting, which we’ll call <code>ifasting</code>) and a
specific exercise regimen (a brisk 30 minute walk every day, which we’ll
just call <code>exercise</code>). The goal (“success”) is to lose at least five
pounds by the end of the trial period. We’ve set up three treatment
groups, as follows:</p>
<ul>
<li>200 subjects try exercise alone</li>
<li>300 subjects try ifasting alone</li>
<li>300 subjects try ifasting plus exercise</li>
</ul>
<p>Prior to the trial, all the subjects led fairly sedentary lifestyles,
and weren’t dieting in any formal way.</p>
<p>For these subjects, one might reasonably expect that neither exercise
nor ifasting would be <em>less</em> successful for losing weight than doing
nothing. One would also reasonably expect that ifasting plus exercise
should do no worse than doing either one alone. Therefore, modeling the
results of such an experiment as a logistic regression should lead to a
model where the coefficients <mjx-container class="MathJax" jax="SVG" style="direction: ltr; position: relative;"><svg style="overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="7.349ex" height="2.262ex" role="img" focusable="false" viewBox="0 -705 3248.3 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width: 3;"/></g><g data-mml-node="TeXAtom" transform="translate(599,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(895,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(1424,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(1893,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(2254,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(2599,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(3199,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z" style="stroke-width: 3;"/></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>β</mi><mrow data-mjx-texclass="ORD"><mi>i</mi><mi>f</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax" jax="SVG" style="direction: ltr; position: relative;"><svg style="overflow: visible; min-height: 1px; min-width: 1px; vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="7.336ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 3242.7 899" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width: 3;"/></g><g data-mml-node="TeXAtom" transform="translate(599,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(466,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(1038,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(1504,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(1955,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(2388,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(2733,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z" style="stroke-width: 3;"/></g><g data-mml-node="mi" transform="translate(3202,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width: 3;"/></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; position: absolute; padding: 1px 0px 0px 0px; border: 0px; display: block; width: auto; overflow: hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>β</mi><mrow data-mjx-texclass="ORD"><mi>e</mi><mi>x</mi><mi>e</mi><mi>r</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>e</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>
are both non-negative, as any treatment should increase the odds that
the subject loses weight.</p>
<p>Let's show an example where our expectations aren't met, in R.</p>
<h3 id="trends-for-individual-subpopulations" tabindex="-1">Trends for individual subpopulations <a class="header-anchor" href="#trends-for-individual-subpopulations">#</a></h3>
<p>Suppose that, unbeknownst to the researchers, there are two
subpopulations amongst the subject. The first, Population A, responds
quite well to the intermittent fasting regimen.</p>
<pre class="language-r" tabindex="0"><code class="language-r">generate_samples <span class="token operator">=</span> <span class="token keyword">function</span><span class="token punctuation">(</span>ifasting<span class="token punctuation">,</span> exercise<span class="token punctuation">,</span> total<span class="token punctuation">,</span> successes<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  failures <span class="token operator">=</span> total<span class="token operator">-</span>successes
  data.frame<span class="token punctuation">(</span>ifasting <span class="token operator">=</span> ifasting<span class="token punctuation">,</span>
             exercise <span class="token operator">=</span> exercise<span class="token punctuation">,</span>
             success <span class="token operator">=</span> c<span class="token punctuation">(</span>rep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> successes<span class="token punctuation">)</span><span class="token punctuation">,</span> rep<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> failures<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             label<span class="token operator">=</span>label<span class="token punctuation">)</span>
<span class="token punctuation">}</span>

<span class="token comment"># population A</span>
popA <span class="token operator">=</span> data.table<span class="token operator">::</span>rbindlist<span class="token punctuation">(</span>list<span class="token punctuation">(</span>
  generate_samples<span class="token punctuation">(</span>ifasting<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> exercise<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> successes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"A"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  generate_samples<span class="token punctuation">(</span>ifasting<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> exercise<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> successes<span class="token operator">=</span><span class="token number">160</span><span class="token punctuation">,</span> <span class="token string">"A"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  generate_samples<span class="token punctuation">(</span>ifasting<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> exercise<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> successes<span class="token operator">=</span><span class="token number">90</span><span class="token punctuation">,</span> <span class="token string">"A"</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># model just on population A</span>
mA <span class="token operator">=</span> glm<span class="token punctuation">(</span>success <span class="token operator">~</span> ifasting <span class="token operator">+</span> exercise<span class="token punctuation">,</span> data<span class="token operator">=</span>popA<span class="token punctuation">,</span> family<span class="token operator">=</span>binomial<span class="token punctuation">)</span>
summary<span class="token punctuation">(</span>mA<span class="token punctuation">)</span></code></pre>
<pre><code>
    ## 
    ## Call:
    ## glm(formula = success ~ ifasting + exercise, family = binomial, 
    ##     data = popA)
    ## 
    ## Coefficients:
    ##             Estimate Std. Error z value Pr(&gt;|z|)    
    ## (Intercept)  -4.7028     0.8078  -5.822 5.82e-09 ***
    ## ifasting      6.0890     0.7882   7.725 1.12e-14 ***
    ## exercise      0.8109     0.3773   2.149   0.0316 *  
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for binomial family taken to be 1)
    ## 
    ##     Null deviance: 527.16  on 399  degrees of freedom
    ## Residual deviance: 284.79  on 397  degrees of freedom
    ## AIC: 290.79
    ## 
    ## Number of Fisher Scoring iterations: 6
</code></pre>
<p>As expected, the coefficients for <code>ifasting</code> and <code>exercise</code> are both
positive. We can look at the rates that the model predicts.</p>
<pre class="language-r" tabindex="0"><code class="language-r"><span class="token comment"># small frame to represent all possible states</span>
testdata <span class="token operator">=</span> data.frame<span class="token punctuation">(</span>
  ifasting <span class="token operator">=</span> c<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  exercise <span class="token operator">=</span> c<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># get the success rates for each state</span>
testdata<span class="token operator">$</span>predictA <span class="token operator">=</span> predict<span class="token punctuation">(</span>mA<span class="token punctuation">,</span> newdata<span class="token operator">=</span>testdata<span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"response"</span><span class="token punctuation">)</span>
testdata</code></pre>
<pre><code>
    ##   ifasting exercise    predictA
    ## 1        0        0 0.008988764
    ## 2        0        1 0.020000000
    ## 3        1        0 0.800000000
    ## 4        1        1 0.900000000
</code></pre>
<pre class="language-r" tabindex="0"><code class="language-r"><span class="token comment"># confirm it by doing the averages by hand</span>
library<span class="token punctuation">(</span>poorman<span class="token punctuation">,</span> warn.conflicts <span class="token operator">=</span> <span class="token boolean">FALSE</span><span class="token punctuation">)</span> <span class="token comment"># for data-wrangling; uses dplyr API</span>

popA <span class="token operator">|</span><span class="token operator">></span> 
  mutate<span class="token punctuation">(</span>gp <span class="token operator">=</span> ifelse<span class="token punctuation">(</span>ifasting <span class="token operator">&amp;</span> exercise<span class="token punctuation">,</span> <span class="token string">'both'</span><span class="token punctuation">,</span>
                     ifelse<span class="token punctuation">(</span>ifasting<span class="token punctuation">,</span> <span class="token string">'ifast alone'</span><span class="token punctuation">,</span> <span class="token string">'exercise alone'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">|</span><span class="token operator">></span>
  group_by<span class="token punctuation">(</span>gp<span class="token punctuation">)</span> <span class="token operator">|</span><span class="token operator">></span>
  summarize<span class="token punctuation">(</span>success_rate <span class="token operator">=</span> mean<span class="token punctuation">(</span>success<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<pre><code>
    ##               gp success_rate
    ## 1           both         0.90
    ## 2 exercise alone         0.02
    ## 3    ifast alone         0.80
</code></pre>
<p>For Population A, exercise alone has a 2% success rate, intermitting
fasting an 80% success rate, and both together have a 90% success rate.</p>
<p>There is also another population, Population B, that has what you might
call a “stickier” metabolism. For them, intermittent fasting is not
quite as effective.</p>
<pre class="language-r" tabindex="0"><code class="language-r">popB <span class="token operator">=</span> data.table<span class="token operator">::</span>rbindlist<span class="token punctuation">(</span>list<span class="token punctuation">(</span>
  generate_samples<span class="token punctuation">(</span>ifasting<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> exercise<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> successes<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  generate_samples<span class="token punctuation">(</span>ifasting<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> exercise<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> successes<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  generate_samples<span class="token punctuation">(</span>ifasting<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> exercise<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> successes<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># model just on population B</span>
mB <span class="token operator">=</span> glm<span class="token punctuation">(</span>success <span class="token operator">~</span> ifasting <span class="token operator">+</span> exercise<span class="token punctuation">,</span> data<span class="token operator">=</span>popB<span class="token punctuation">,</span> family<span class="token operator">=</span>binomial<span class="token punctuation">)</span>
summary<span class="token punctuation">(</span>mB<span class="token punctuation">)</span></code></pre>
<pre><code>    ## 
    ## Call:
    ## glm(formula = success ~ ifasting + exercise, family = binomial, 
    ##     data = popB)
    ## 
    ## Coefficients:
    ##             Estimate Std. Error z value Pr(&gt;|z|)    
    ## (Intercept)  -5.0006     1.0353  -4.830 1.36e-06 ***
    ## ifasting      4.5951     1.0149   4.528 5.97e-06 ***
    ## exercise      0.4055     0.2483   1.633    0.103    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for binomial family taken to be 1)
    ## 
    ##     Null deviance: 519.18  on 399  degrees of freedom
    ## Residual deviance: 423.06  on 397  degrees of freedom
    ## AIC: 429.06
    ## 
    ## Number of Fisher Scoring iterations: 7
</code></pre>
<pre class="language-r" tabindex="0"><code class="language-r">testdata<span class="token operator">$</span>predictB <span class="token operator">=</span> predict<span class="token punctuation">(</span>mB<span class="token punctuation">,</span> newdata<span class="token operator">=</span>testdata<span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"response"</span><span class="token punctuation">)</span>
testdata</code></pre>
<pre><code>    ##   ifasting exercise    predictA    predictB
    ## 1        0        0 0.008988764 0.006688963
    ## 2        0        1 0.020000000 0.010000000
    ## 3        1        0 0.800000000 0.400000000
    ## 4        1        1 0.900000000 0.500000000
</code></pre>
<p>For Population B, the coefficients for <code>ifasting</code> and <code>exercise</code> are
still positive, but smaller, and the success rates are lower.</p>
<h3 id="trends-for-the-whole-population" tabindex="-1">Trends for the whole population <a class="header-anchor" href="#trends-for-the-whole-population">#</a></h3>
<p>Now what happens if we model both populations together?</p>
<pre class="language-r" tabindex="0"><code class="language-r">popAll <span class="token operator">=</span> data.table<span class="token operator">::</span>rbindlist<span class="token punctuation">(</span>list<span class="token punctuation">(</span>popA<span class="token punctuation">,</span> popB<span class="token punctuation">)</span><span class="token punctuation">)</span>
mAll <span class="token operator">=</span> glm<span class="token punctuation">(</span>success <span class="token operator">~</span> ifasting <span class="token operator">+</span> exercise<span class="token punctuation">,</span> data<span class="token operator">=</span>popAll<span class="token punctuation">,</span> family<span class="token operator">=</span>binomial<span class="token punctuation">)</span>
summary<span class="token punctuation">(</span>mAll<span class="token punctuation">)</span></code></pre>
<pre><code>    ## 
    ## Call:
    ## glm(formula = success ~ ifasting + exercise, family = binomial, 
    ##     data = popAll)
    ## 
    ## Coefficients:
    ##             Estimate Std. Error z value Pr(&gt;|z|)    
    ## (Intercept)  -4.0380     0.6062  -6.661 2.72e-11 ***
    ## ifasting      4.7311     0.5937   7.969 1.60e-15 ***
    ## exercise     -0.1466     0.1713  -0.856    0.392    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for binomial family taken to be 1)
    ## 
    ##     Null deviance: 1108.79  on 799  degrees of freedom
    ## Residual deviance:  807.36  on 797  degrees of freedom
    ## AIC: 813.36
    ## 
    ## Number of Fisher Scoring iterations: 6
</code></pre>
<p>Now exercise has a negative coefficient, making it appear that
intermittent fasting and exercise together has <em>worse</em> outcomes than
intermittent fasting alone!</p>
<pre class="language-r" tabindex="0"><code class="language-r">testdata<span class="token operator">$</span>predictAll <span class="token operator">=</span> predict<span class="token punctuation">(</span>mAll<span class="token punctuation">,</span> newdata<span class="token operator">=</span>testdata<span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"response"</span><span class="token punctuation">)</span>
testdata</code></pre>
<pre><code>    ##   ifasting exercise    predictA    predictB predictAll
    ## 1        0        0 0.008988764 0.006688963 0.01732739
    ## 2        0        1 0.020000000 0.010000000 0.01500000
    ## 3        1        0 0.800000000 0.400000000 0.66666667
    ## 4        1        1 0.900000000 0.500000000 0.63333333
</code></pre>
<p>This is an example of how Simpson’s paradox might manifest itself in a
logistic regression model, and it’s due to the unmodelled confounding
variable, population type. This, plus some bad luck in the relative sizes of the
treatment groups with respect to population type, lead to the above, counterintuitive, results.</p>
<p>Simpson’s paradox isn’t the only reason for a coefficient with an
unexpected sign; this can also happen when the data is <a href="https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faqwhat-is-complete-or-quasi-complete-separation-in-logistic-regression-and-what-are-some-strategies-to-deal-with-the-issue/">separated or
quasi-separated</a>.
In our case, this would happen if any of the treatment groups perfectly
predicted outcome (that is, if any treatment group completely succeeded
or completely failed). Let’s check for that.</p>
<pre class="language-r" tabindex="0"><code class="language-r">popAll <span class="token operator">|</span><span class="token operator">></span> 
  mutate<span class="token punctuation">(</span>gp <span class="token operator">=</span> ifelse<span class="token punctuation">(</span>ifasting <span class="token operator">&amp;</span> exercise<span class="token punctuation">,</span> <span class="token string">'both'</span><span class="token punctuation">,</span>
                     ifelse<span class="token punctuation">(</span>ifasting<span class="token punctuation">,</span> <span class="token string">'ifast alone'</span><span class="token punctuation">,</span> <span class="token string">'exercise alone'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">|</span><span class="token operator">></span>
  group_by<span class="token punctuation">(</span>gp<span class="token punctuation">)</span> <span class="token operator">|</span><span class="token operator">></span>
  summarize<span class="token punctuation">(</span>success_rate <span class="token operator">=</span> mean<span class="token punctuation">(</span>success<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<pre><code>    ##               gp success_rate
    ## 1           both    0.6333333
    ## 2 exercise alone    0.0150000
    ## 3    ifast alone    0.6666667
</code></pre>
<p>So separation isn’t the problem; the unmodelled confounding variable is.</p>
<h2 id="resolving-the-issue" tabindex="-1">Resolving the issue <a class="header-anchor" href="#resolving-the-issue">#</a></h2>
<p>When faced with a counterintuitive result, try to determine if there's
a factor you're not taking into account.</p>
<p>In this example, if the researchers did have access to the subjects’ population type,
then they could control for that in the modelling.</p>
<pre class="language-r" tabindex="0"><code class="language-r">mAllplus <span class="token operator">=</span> glm<span class="token punctuation">(</span>success <span class="token operator">~</span> ifasting <span class="token operator">+</span> exercise <span class="token operator">+</span> label<span class="token punctuation">,</span> data<span class="token operator">=</span>popAll<span class="token punctuation">,</span> family<span class="token operator">=</span>binomial<span class="token punctuation">)</span>
summary<span class="token punctuation">(</span>mAllplus<span class="token punctuation">)</span></code></pre>
<pre><code>    ## 
    ## Call:
    ## glm(formula = success ~ ifasting + exercise + label, family = binomial, 
    ##     data = popAll)
    ## 
    ## Coefficients:
    ##             Estimate Std. Error z value Pr(&gt;|z|)    
    ## (Intercept)  -4.1433     0.6156  -6.731 1.69e-11 ***
    ## ifasting      5.5836     0.6154   9.073  &lt; 2e-16 ***
    ## exercise      0.5231     0.2037   2.568   0.0102 *  
    ## labelB       -1.9172     0.2103  -9.118  &lt; 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for binomial family taken to be 1)
    ## 
    ##     Null deviance: 1108.79  on 799  degrees of freedom
    ## Residual deviance:  709.51  on 796  degrees of freedom
    ## AIC: 717.51
    ## 
    ## Number of Fisher Scoring iterations: 7
</code></pre>
<p>As expected, both <code>ifasting</code> and <code>exercise</code> now have positive (and
significant, to p=0.05) coefficients, indicating that both actions
increase the probability of weight loss, and doing them both increases
it even more.</p>
<p>The model also correctly identifies that subjects of population type B
have a (significantly) lower success rate than subjects from Population
A.</p>

</article>
<ul class="links-nextprev"><li>Previous: <a href="/blog/2024-05-27-algorithmic-art/">Algorithmic Art</a></li><li>Next: <a href="/blog/2024-08-20-saturated-models/">Adjusting Saturated Multivariate Linear Models</a></li>
</ul>

		</main>

		<!-- footer -->
		<hr />

<div class="footer-container">
	<p>&copy; 2024 Nina B. Zumel</p>
	<div class="social_icons">
	    <a
			href="mailto:nzumel@win-vector.com?subject=Comment%20from%20Website"
			aria-label="Email"
			target="_blank"
			rel="noopener noreferrer"
		>
			<i class="fas fa-fw fa-envelope"></i>
		</a>
		<a
			href="https://github.com/ninazumel"
			aria-label="GitHub"
			target="_blank"
			rel="noopener noreferrer"
		>
			<i class="fa-brands fa-github"></i>
		</a>
		<a
			href="https://www.linkedin.com/in/ninazumel/"
			aria-label="LinkedIn"
			target="_blank"
			rel="noopener noreferrer"
		>
			<i class="fa-brands fa-linkedin"></i>
		</a>
		<a
			href="/feed.xml"
			aria-label="RSS"
			target="_blank"
			rel="noopener noreferrer"
		>
			<i class="fa fa-fw fa-rss-square"></i>
		</a>

	</div>
</div>
		<!-- /footer-- >

		<!-- Current page: /blog/2024-07-16-simpsons-paradox-as-logistic-regression/ -->
	</body>
</html>
